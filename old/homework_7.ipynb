{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_df = train_gen.flow_from_directory('./data/train', target_size=(150, 150), batch_size=32)\n",
    "train_df.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_df = test_gen.flow_from_directory('./data/test', target_size=(150, 150), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to develop the model with following structure:\n",
    "\n",
    "The shape for input should be (150, 150, 3)\n",
    "\n",
    "Next, create a convolutional layer (Conv2D):\n",
    "\n",
    "    Use 32 filters\n",
    "    Kernel size should be (3, 3) (that's the size of the filter)\n",
    "    Use 'relu' as activation\n",
    "    Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "    Set the pooling size to (2, 2)\n",
    "    Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "\n",
    "Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "\n",
    "Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "\n",
    "The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use SGD with the following parameters:\n",
    "\n",
    "SGD(lr=0.002, momentum=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Since we have a binary classification problem, what is the best loss function for us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=SGD(learning_rate=0.002, momentum=0.8),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "What's the number of parameters in the convolutional layer of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1./255)\n",
    "test = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train.flow_from_directory('./data/train',\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size=20,\n",
    "                                            class_mode='binary')\n",
    "test_generator = test.flow_from_directory('./data/test',\n",
    "                                          target_size=(150, 150),\n",
    "                                          batch_size=20,\n",
    "                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\49162\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "184/184 [==============================] - 53s 286ms/step - loss: 0.6696 - acc: 0.5662 - val_loss: 0.6461 - val_acc: 0.5479\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.6266 - acc: 0.6342 - val_loss: 0.5941 - val_acc: 0.6536\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.5767 - acc: 0.7082 - val_loss: 0.6085 - val_acc: 0.6645\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.5349 - acc: 0.7493 - val_loss: 0.5495 - val_acc: 0.7211\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.5079 - acc: 0.7691 - val_loss: 0.5350 - val_acc: 0.7244\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.4793 - acc: 0.7773 - val_loss: 0.5189 - val_acc: 0.7691\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.4588 - acc: 0.7925 - val_loss: 0.5053 - val_acc: 0.7712\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.4334 - acc: 0.8053 - val_loss: 0.4920 - val_acc: 0.7778\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.4006 - acc: 0.8259 - val_loss: 0.5121 - val_acc: 0.7636\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.3691 - acc: 0.8428 - val_loss: 0.5041 - val_acc: 0.7582\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "What is the median of training accuracy for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7731846570968628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "What is the standard deviation of training loss for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09230264282772438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* rotation_range=50,\n",
    "* width_shift_range=0.1,\n",
    "* height_shift_range=0.1,\n",
    "* zoom_range=0.1,\n",
    "* horizontal_flip=True,\n",
    "* fill_mode='nearest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_aug = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=50,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_aug.flow_from_directory('./data/train',\n",
    "                                                target_size=(150, 150),\n",
    "                                                batch_size=20,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.5031 - acc: 0.7642 - val_loss: 0.5009 - val_acc: 0.7658\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.4849 - acc: 0.7762 - val_loss: 0.4801 - val_acc: 0.7745\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.4746 - acc: 0.7805 - val_loss: 0.4872 - val_acc: 0.7712\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 30s 164ms/step - loss: 0.4757 - acc: 0.7800 - val_loss: 0.5139 - val_acc: 0.7429\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.4769 - acc: 0.7876 - val_loss: 0.4759 - val_acc: 0.7712\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 30s 164ms/step - loss: 0.4678 - acc: 0.7843 - val_loss: 0.4510 - val_acc: 0.7930\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.4643 - acc: 0.7868 - val_loss: 0.5205 - val_acc: 0.7538\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 31s 168ms/step - loss: 0.4700 - acc: 0.7841 - val_loss: 0.4591 - val_acc: 0.7887\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.4565 - acc: 0.7928 - val_loss: 0.4594 - val_acc: 0.7952\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.4626 - acc: 0.7822 - val_loss: 0.4707 - val_acc: 0.7800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48185963928699493"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7794117480516434"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_acc'][6:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
